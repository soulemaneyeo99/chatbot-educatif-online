"""
Client OpenAI API pour le Chatbot √âducatif Vocal
===============================================

Interface avec l'API OpenAI GPT pour g√©n√©rer des r√©ponses √©ducatives
adapt√©es aux personnes peu alphab√©tis√©es.

Utilisation:
    from app.services.openai_client import OpenAIClient
    
    client = OpenAIClient(api_key="sk-...")
    response = await client.generate_response("Explique-moi les fractions")
"""

import asyncio
import json
import time
from typing import Dict, List, Optional, Any, Union
import logging

import openai
from openai import AsyncOpenAI

from app.utils.exceptions import (
    ClaudeAPIError,  # On garde le m√™me nom pour compatibilit√©
    ClaudeTimeoutError,
    ClaudeQuotaExceededError, 
    ClaudeInvalidModelError,
    ChatbotException
)
from app.utils.logger import log_metrics


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üéØ PROMPTS SYST√àME POUR L'√âDUCATION
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

EDUCATION_SYSTEM_PROMPT = """Tu es un assistant √©ducatif vocal sp√©cialement con√ßu pour aider les personnes peu alphab√©tis√©es √† apprendre.

## üéØ TON R√îLE
- Tu es un √©ducateur patient, bienveillant et encourageant
- Tu adaptes tes explications au niveau de compr√©hension de chaque personne
- Tu utilises un langage simple, clair et accessible
- Tu encourages toujours l'apprentissage et la curiosit√©

## üìö PRINCIPES P√âDAGOGIQUES
1. **Simplicit√©** : Utilise des mots simples et des phrases courtes
2. **Analogies** : Utilise des comparaisons avec des choses du quotidien
3. **R√©p√©tition** : N'h√©site pas √† r√©p√©ter les concepts importants
4. **Encouragement** : F√©licite les efforts et les progr√®s
5. **Patience** : Jamais de jugement, toujours de la bienveillance

## üó£Ô∏è STYLE DE COMMUNICATION
- **Ton familier et chaleureux** (tu peux tutoyer)
- **Phrases courtes** (maximum 15-20 mots)
- **Vocabulaire du quotidien** (√©vite les termes techniques)
- **Structure claire** : introduction ‚Üí explication ‚Üí r√©sum√©
- **Questions pour v√©rifier** la compr√©hension

## ‚úÖ BONNES PRATIQUES
- Commence par saluer chaleureusement
- Demande le niveau de d√©tail souhait√© si n√©cessaire
- Utilise des exemples concrets et familiers
- Propose des exercices pratiques simples
- Termine par un encouragement

## ‚ùå √Ä √âVITER ABSOLUMENT
- Vocabulaire complexe ou technique
- Phrases trop longues ou compliqu√©es
- Ton condescendant ou professoral
- R√©f√©rences culturelles obscures
- D√©couragement face aux erreurs

## üé™ EXEMPLES D'APPROCHE
Pour expliquer les fractions :
"Les fractions, c'est comme partager une pizza ! Si tu coupes ta pizza en 4 parts √©gales et que tu en prends 1, tu as 1/4 de la pizza. Simple, non ?"

Pour la g√©ographie :
"La France, c'est notre pays. Imagine-le comme ta maison, mais en tr√®s tr√®s grand. Paris, c'est comme le salon principal o√π habitent beaucoup de personnes."

R√©ponds TOUJOURS dans cet esprit √©ducatif, patient et bienveillant."""


RAG_SYSTEM_PROMPT = """Tu es un assistant √©ducatif qui s'appuie sur des documents p√©dagogiques pour r√©pondre aux questions.

## üìñ UTILISATION DES DOCUMENTS
Tu as acc√®s √† des documents √©ducatifs qui contiennent des informations fiables et adapt√©es √† ton public.

**QUAND utiliser les documents :**
- La question porte sur un sujet sp√©cifique couvert dans les documents
- Tu as besoin d'informations pr√©cises et v√©rifi√©es
- L'utilisateur demande des d√©tails sur un cours particulier

**COMMENT utiliser les documents :**
1. Lis attentivement le contenu fourni
2. Adapte le langage √† ton public (simplification si n√©cessaire)
3. Ajoute tes propres explications pour clarifier
4. Ne cite jamais directement les documents (adapte toujours)

**QUAND NE PAS utiliser les documents :**
- Pour des conversations g√©n√©rales
- Pour des encouragements et motivations
- Pour des explications de base que tu ma√Ætrises d√©j√†

## üéØ ADAPTATION DU CONTENU
M√™me avec des documents, respecte TOUJOURS les principes :
- Langage simple et accessible
- Explications courtes et claires
- Exemples du quotidien
- Ton bienveillant et encourageant

Si un document est trop complexe, SIMPLIFIE-LE pour ton public."""


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üèóÔ∏è CLIENT OPENAI API
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class OpenAIClient:
    """
    Client pour interagir avec l'API OpenAI GPT.
    
    G√®re l'authentification, les prompts √©ducatifs, la gestion d'erreurs,
    et l'int√©gration avec le syst√®me RAG.
    """
    
    def __init__(
        self,
        api_key: str,
        model: str = "gpt-3.5-turbo",
        max_tokens: int = 1000,
        temperature: float = 0.7,
        timeout: int = 30,
        logger: Optional[logging.Logger] = None
    ):
        """
        Initialise le client OpenAI.
        
        Args:
            api_key: Cl√© API OpenAI
            model: Mod√®le GPT √† utiliser
            max_tokens: Nombre maximum de tokens
            temperature: Temp√©rature de g√©n√©ration (0-1)
            timeout: Timeout en secondes
            logger: Logger optionnel
        """
        self.api_key = api_key
        self.model = model
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.timeout = timeout
        self.logger = logger or logging.getLogger(__name__)
        
        # Validation du mod√®le
        self._validate_model()
        
        # Client OpenAI async
        self.client = AsyncOpenAI(
            api_key=api_key,
            timeout=timeout
        )
        
        # Statistiques
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_tokens_used": 0,
            "average_response_time": 0.0
        }
        
        self.logger.info(f"ü§ñ Client OpenAI initialis√© - Mod√®le: {model}")
    
    def _validate_model(self):
        """Valide que le mod√®le est support√©."""
        supported_models = [
            "gpt-4",
            "gpt-4-turbo",
            "gpt-4-turbo-preview", 
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-16k",
            "gpt-4o",
            "gpt-4o-mini"
        ]
        
        if self.model not in supported_models:
            raise ClaudeInvalidModelError(self.model)
    
    def _handle_api_error(self, error: Exception) -> ClaudeAPIError:
        """
        Convertit les erreurs API en exceptions m√©tier.
        
        Args:
            error: Exception originale
            
        Returns:
            ClaudeAPIError: Exception m√©tier appropri√©e
        """
        error_str = str(error).lower()
        
        # Timeout
        if "timeout" in error_str or isinstance(error, asyncio.TimeoutError):
            return ClaudeTimeoutError(self.timeout)
        
        # Quota/Rate limit d√©pass√©
        if "rate limit" in error_str or "quota" in error_str or "429" in error_str:
            return ClaudeQuotaExceededError()
        
        # Mod√®le invalide
        if "model" in error_str and ("invalid" in error_str or "not found" in error_str):
            return ClaudeInvalidModelError(self.model)
        
        # Cl√© API invalide
        if "authentication" in error_str or "api key" in error_str or "401" in error_str:
            return ClaudeAPIError(
                message="Cl√© API OpenAI invalide",
                details="V√©rifiez votre cl√© API dans la configuration",
                status_code=401
            )
        
        # Erreur g√©n√©rique
        return ClaudeAPIError(
            message="Erreur de l'assistant IA",
            details=str(error)
        )
    
    def _update_stats(self, success: bool, response_time: float, tokens_used: int = 0):
        """Met √† jour les statistiques d'usage."""
        self.stats["total_requests"] += 1
        
        if success:
            self.stats["successful_requests"] += 1
            self.stats["total_tokens_used"] += tokens_used
            
            # Moyenne glissante du temps de r√©ponse
            current_avg = self.stats["average_response_time"]
            total_requests = self.stats["total_requests"]
            self.stats["average_response_time"] = (
                (current_avg * (total_requests - 1) + response_time) / total_requests
            )
        else:
            self.stats["failed_requests"] += 1
        
        # M√©triques globales
        log_metrics.log_claude_call()  # On garde le m√™me nom pour la compatibilit√©
    
    async def generate_response(
        self,
        user_message: str,
        context_documents: Optional[List[Dict[str, Any]]] = None,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        system_prompt_override: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        G√©n√®re une r√©ponse √©ducative √† partir d'un message utilisateur.
        
        Args:
            user_message: Message de l'utilisateur
            context_documents: Documents RAG pour le contexte
            conversation_history: Historique de la conversation
            system_prompt_override: Prompt syst√®me personnalis√©
            
        Returns:
            Dict: R√©ponse avec m√©tadonn√©es
            
        Raises:
            ClaudeAPIError: Si erreur lors de l'appel API
        """
        start_time = time.time()
        
        try:
            # Construction du prompt syst√®me
            system_prompt = system_prompt_override or self._build_system_prompt(context_documents)
            
            # Construction des messages
            messages = self._build_messages(user_message, conversation_history, context_documents, system_prompt)
            
            self.logger.debug(f"üîµ Appel OpenAI - Mod√®le: {self.model}, Messages: {len(messages)}")
            
            # Appel √† l'API OpenAI
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                timeout=self.timeout
            )
            
            # Extraction de la r√©ponse
            response_text = response.choices[0].message.content if response.choices else ""
            
            # Calcul des m√©triques
            response_time = (time.time() - start_time) * 1000  # ms
            tokens_used = response.usage.total_tokens if response.usage else 0
            
            # Mise √† jour des stats
            self._update_stats(True, response_time, tokens_used)
            
            # Logging
            self.logger.info(
                f"‚úÖ R√©ponse OpenAI g√©n√©r√©e - "
                f"Tokens: {tokens_used}, Temps: {response_time:.0f}ms"
            )
            
            # Construction de la r√©ponse enrichie
            result = {
                "response": response_text,
                "model": self.model,
                "tokens_used": tokens_used,
                "response_time_ms": response_time,
                "has_context": bool(context_documents),
                "context_documents_count": len(context_documents) if context_documents else 0,
                "metadata": {
                    "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                    "completion_tokens": response.usage.completion_tokens if response.usage else 0,
                    "finish_reason": response.choices[0].finish_reason if response.choices else None,
                    "generated_at": time.time()
                }
            }
            
            return result
            
        except asyncio.TimeoutError:
            self._update_stats(False, (time.time() - start_time) * 1000)
            raise ClaudeTimeoutError(self.timeout)
            
        except Exception as e:
            self._update_stats(False, (time.time() - start_time) * 1000)
            self.logger.error(f"‚ùå Erreur OpenAI API: {e}")
            raise self._handle_api_error(e)
    
    def _build_system_prompt(self, context_documents: Optional[List[Dict[str, Any]]] = None) -> str:
        """
        Construit le prompt syst√®me selon le contexte.
        
        Args:
            context_documents: Documents RAG optionnels
            
        Returns:
            str: Prompt syst√®me complet
        """
        if context_documents:
            return RAG_SYSTEM_PROMPT
        else:
            return EDUCATION_SYSTEM_PROMPT
    
    def _build_messages(
        self,
        user_message: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        context_documents: Optional[List[Dict[str, Any]]] = None,
        system_prompt: str = ""
    ) -> List[Dict[str, str]]:
        """
        Construit la liste des messages pour OpenAI.
        
        Args:
            user_message: Message utilisateur actuel  
            conversation_history: Historique des √©changes
            context_documents: Documents de contexte RAG
            system_prompt: Prompt syst√®me
            
        Returns:
            List: Messages format√©s pour l'API OpenAI
        """
        messages = []
        
        # Message syst√®me (toujours en premier)
        if system_prompt:
            messages.append({
                "role": "system",
                "content": system_prompt
            })
        
        # Ajout de l'historique de conversation
        if conversation_history:
            for exchange in conversation_history[-5:]:  # Garde seulement les 5 derniers √©changes
                if exchange.get("user"):
                    messages.append({
                        "role": "user",
                        "content": exchange["user"]
                    })
                if exchange.get("assistant"):
                    messages.append({
                        "role": "assistant", 
                        "content": exchange["assistant"]
                    })
        
        # Construction du message utilisateur actuel
        current_message = user_message
        
        # Ajout du contexte RAG si disponible
        if context_documents:
            context_text = self._format_context_documents(context_documents)
            current_message = f"""Contexte √©ducatif disponible :
{context_text}

Question de l'utilisateur : {user_message}

R√©ponds en utilisant le contexte ci-dessus si pertinent, sinon r√©ponds avec tes connaissances g√©n√©rales. Adapte toujours ton langage pour des personnes peu alphab√©tis√©es."""
        
        messages.append({
            "role": "user",
            "content": current_message
        })
        
        return messages
    
    def _format_context_documents(self, context_documents: List[Dict[str, Any]]) -> str:
        """
        Formate les documents de contexte pour le prompt.
        
        Args:
            context_documents: Documents RAG avec scores
            
        Returns:
            str: Contexte format√©
        """
        if not context_documents:
            return ""
        
        context_parts = []
        for i, doc in enumerate(context_documents[:3], 1):  # Max 3 documents
            content = doc.get("content", "").strip()
            score = doc.get("score", 0.0)
            
            if content:
                context_parts.append(f"Document {i} (pertinence: {score:.2f}) :\n{content}")
        
        return "\n\n".join(context_parts)
    
    async def generate_simple_response(self, user_message: str) -> str:
        """
        G√©n√®re une r√©ponse simple sans contexte RAG.
        
        Args:
            user_message: Message de l'utilisateur
            
        Returns:
            str: R√©ponse g√©n√©r√©e
        """
        result = await self.generate_response(user_message)
        return result["response"]
    
    async def test_connection(self) -> Dict[str, Any]:
        """
        Teste la connexion √† l'API OpenAI.
        
        Returns:
            Dict: R√©sultat du test
        """
        try:
            start_time = time.time()
            
            # Test simple avec un message minimal
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Tu es un assistant de test."},
                    {"role": "user", "content": "Dis juste 'Test OK'"}
                ],
                max_tokens=10,
                temperature=0
            )
            
            response_time = (time.time() - start_time) * 1000
            
            return {
                "success": True,
                "model": self.model,
                "response_time_ms": response_time,
                "response": response.choices[0].message.content if response.choices else "",
                "tokens_used": response.usage.total_tokens if response.usage else 0
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "model": self.model
            }
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Retourne les statistiques d'usage du client.
        
        Returns:
            Dict: Statistiques d√©taill√©es
        """
        return {
            **self.stats,
            "success_rate": (
                self.stats["successful_requests"] / max(self.stats["total_requests"], 1)
            ) * 100,
            "model": self.model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature
        }
    
    def reset_stats(self):
        """Remet √† z√©ro les statistiques."""
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_tokens_used": 0,
            "average_response_time": 0.0
        }
        self.logger.info("üìä Statistiques remises √† z√©ro")
    
    async def close(self):
        """Ferme proprement le client."""
        try:
            await self.client.close()
            self.logger.info("üîí Client OpenAI ferm√©")
        except Exception as e:
            self.logger.warning(f"Erreur lors de la fermeture: {e}")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üß™ FONCTIONS DE TEST
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def test_openai_client():
    """Teste le client OpenAI avec diff√©rents sc√©narios."""
    import os
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå OPENAI_API_KEY manquante dans l'environnement")
        return
    
    print("üß™ Test du client OpenAI...")
    
    client = OpenAIClient(
        api_key=api_key,
        model="gpt-3.5-turbo",
        max_tokens=100
    )
    
    # Test de connexion
    print("\n1. Test de connexion...")
    connection_test = await client.test_connection()
    if connection_test["success"]:
        print(f"‚úÖ Connexion OK - {connection_test['response']}")
    else:
        print(f"‚ùå Connexion √©chou√©e: {connection_test['error']}")
        return
    
    # Test de r√©ponse simple
    print("\n2. Test de r√©ponse √©ducative...")
    try:
        response = await client.generate_simple_response(
            "Explique-moi ce que c'est qu'une addition"
        )
        print(f"‚úÖ R√©ponse: {response[:100]}...")
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
    
    # Test avec contexte RAG
    print("\n3. Test avec contexte RAG...")
    mock_documents = [
        {
            "content": "L'addition est une op√©ration qui permet de rassembler plusieurs nombres pour en obtenir un seul, appel√© somme.",
            "score": 0.95
        }
    ]
    
    try:
        result = await client.generate_response(
            "Comment faire une addition ?",
            context_documents=mock_documents
        )
        print(f"‚úÖ R√©ponse avec RAG: {result['response'][:100]}...")
        print(f"   Tokens utilis√©s: {result['tokens_used']}")
    except Exception as e:
        print(f"‚ùå Erreur RAG: {e}")
    
    # Statistiques
    print("\n4. Statistiques:")
    stats = client.get_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    # Fermeture
    await client.close()
    print("\n‚úÖ Test termin√©!")


if __name__ == "__main__":
    asyncio.run(test_openai_client())