"""
Client OpenAI API pour le Chatbot Ã‰ducatif Vocal
===============================================

Interface avec l'API OpenAI GPT pour gÃ©nÃ©rer des rÃ©ponses Ã©ducatives
adaptÃ©es aux personnes peu alphabÃ©tisÃ©es.

Utilisation:
    from app.services.openai_client import OpenAIClient
    
    client = OpenAIClient(api_key="sk-...")
    response = await client.generate_response("Explique-moi les fractions")
"""

import asyncio
import json
import time
from typing import Dict, List, Optional, Any, Union
import logging

import openai
from openai import AsyncOpenAI

from app.utils.exceptions import (
    ClaudeAPIError,  # On garde le mÃªme nom pour compatibilitÃ©
    ClaudeTimeoutError,
    ClaudeQuotaExceededError, 
    ClaudeInvalidModelError,
    ChatbotException
)
from app.utils.logger import log_metrics


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ PROMPTS SYSTÃˆME POUR L'Ã‰DUCATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EDUCATION_SYSTEM_PROMPT = """Tu es un assistant Ã©ducatif vocal spÃ©cialement conÃ§u pour aider les personnes peu alphabÃ©tisÃ©es Ã  apprendre.

## ğŸ¯ TON RÃ”LE
- Tu es un Ã©ducateur patient, bienveillant et encourageant
- Tu adaptes tes explications au niveau de comprÃ©hension de chaque personne
- Tu utilises un langage simple, clair et accessible
- Tu encourages toujours l'apprentissage et la curiositÃ©

## ğŸ“š PRINCIPES PÃ‰DAGOGIQUES
1. **SimplicitÃ©** : Utilise des mots simples et des phrases courtes
2. **Analogies** : Utilise des comparaisons avec des choses du quotidien
3. **RÃ©pÃ©tition** : N'hÃ©site pas Ã  rÃ©pÃ©ter les concepts importants
4. **Encouragement** : FÃ©licite les efforts et les progrÃ¨s
5. **Patience** : Jamais de jugement, toujours de la bienveillance

## ğŸ—£ï¸ STYLE DE COMMUNICATION
- **Ton familier et chaleureux** (tu peux tutoyer)
- **Phrases courtes** (maximum 15-20 mots)
- **Vocabulaire du quotidien** (Ã©vite les termes techniques)
- **Structure claire** : introduction â†’ explication â†’ rÃ©sumÃ©
- **Questions pour vÃ©rifier** la comprÃ©hension

## âœ… BONNES PRATIQUES
- Commence par saluer chaleureusement
- Demande le niveau de dÃ©tail souhaitÃ© si nÃ©cessaire
- Utilise des exemples concrets et familiers
- Propose des exercices pratiques simples
- Termine par un encouragement

## âŒ Ã€ Ã‰VITER ABSOLUMENT
- Vocabulaire complexe ou technique
- Phrases trop longues ou compliquÃ©es
- Ton condescendant ou professoral
- RÃ©fÃ©rences culturelles obscures
- DÃ©couragement face aux erreurs

## ğŸª EXEMPLES D'APPROCHE
Pour expliquer les fractions :
"Les fractions, c'est comme partager une pizza ! Si tu coupes ta pizza en 4 parts Ã©gales et que tu en prends 1, tu as 1/4 de la pizza. Simple, non ?"

Pour la gÃ©ographie :
"La France, c'est notre pays. Imagine-le comme ta maison, mais en trÃ¨s trÃ¨s grand. Paris, c'est comme le salon principal oÃ¹ habitent beaucoup de personnes."

RÃ©ponds TOUJOURS dans cet esprit Ã©ducatif, patient et bienveillant."""


RAG_SYSTEM_PROMPT = """Tu es un assistant Ã©ducatif qui s'appuie sur des documents pÃ©dagogiques pour rÃ©pondre aux questions.

## ğŸ“– UTILISATION DES DOCUMENTS
Tu as accÃ¨s Ã  des documents Ã©ducatifs qui contiennent des informations fiables et adaptÃ©es Ã  ton public.

**QUAND utiliser les documents :**
- La question porte sur un sujet spÃ©cifique couvert dans les documents
- Tu as besoin d'informations prÃ©cises et vÃ©rifiÃ©es
- L'utilisateur demande des dÃ©tails sur un cours particulier

**COMMENT utiliser les documents :**
1. Lis attentivement le contenu fourni
2. Adapte le langage Ã  ton public (simplification si nÃ©cessaire)
3. Ajoute tes propres explications pour clarifier
4. Ne cite jamais directement les documents (adapte toujours)

**QUAND NE PAS utiliser les documents :**
- Pour des conversations gÃ©nÃ©rales
- Pour des encouragements et motivations
- Pour des explications de base que tu maÃ®trises dÃ©jÃ 

## ğŸ¯ ADAPTATION DU CONTENU
MÃªme avec des documents, respecte TOUJOURS les principes :
- Langage simple et accessible
- Explications courtes et claires
- Exemples du quotidien
- Ton bienveillant et encourageant

Si un document est trop complexe, SIMPLIFIE-LE pour ton public."""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ—ï¸ CLIENT OPENAI API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class OpenAIClient:
    """
    Client pour interagir avec l'API OpenAI GPT.
    
    GÃ¨re l'authentification, les prompts Ã©ducatifs, la gestion d'erreurs,
    et l'intÃ©gration avec le systÃ¨me RAG.
    """
    
    def __init__(
        self,
        api_key: str,
        model: str = "gpt-3.5-turbo",
        max_tokens: int = 1000,
        temperature: float = 0.7,
        timeout: int = 30,
        logger: Optional[logging.Logger] = None
    ):
        """
        Initialise le client OpenAI.
        
        Args:
            api_key: ClÃ© API OpenAI
            model: ModÃ¨le GPT Ã  utiliser
            max_tokens: Nombre maximum de tokens
            temperature: TempÃ©rature de gÃ©nÃ©ration (0-1)
            timeout: Timeout en secondes
            logger: Logger optionnel
        """
        self.api_key = api_key
        self.model = model
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.timeout = timeout
        self.logger = logger or logging.getLogger(__name__)
        
        # Validation du modÃ¨le
        self._validate_model()
        
        # Client OpenAI async
        self.client = AsyncOpenAI(
            api_key=api_key,
            timeout=timeout
        )
        
        # Statistiques
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_tokens_used": 0,
            "average_response_time": 0.0
        }
        
        self.logger.info(f"ğŸ¤– Client OpenAI initialisÃ© - ModÃ¨le: {model}")
    
    def _validate_model(self):
        """Valide que le modÃ¨le est supportÃ©."""
        supported_models = [
            "gpt-4",
            "gpt-4-turbo",
            "gpt-4-turbo-preview", 
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-16k",
            "gpt-4o",
            "gpt-4o-mini"
        ]
        
        if self.model not in supported_models:
            raise ClaudeInvalidModelError(self.model)
    
    def _handle_api_error(self, error: Exception) -> ClaudeAPIError:
        """
        Convertit les erreurs API en exceptions mÃ©tier.
        
        Args:
            error: Exception originale
            
        Returns:
            ClaudeAPIError: Exception mÃ©tier appropriÃ©e
        """
        error_str = str(error).lower()
        
        # Timeout
        if "timeout" in error_str or isinstance(error, asyncio.TimeoutError):
            return ClaudeTimeoutError(self.timeout)
        
        # Quota/Rate limit dÃ©passÃ©
        if "rate limit" in error_str or "quota" in error_str or "429" in error_str:
            return ClaudeQuotaExceededError()
        
        # ModÃ¨le invalide
        if "model" in error_str and ("invalid" in error_str or "not found" in error_str):
            return ClaudeInvalidModelError(self.model)
        
        # ClÃ© API invalide
        if "authentication" in error_str or "api key" in error_str or "401" in error_str:
            return ClaudeAPIError(
                message="ClÃ© API OpenAI invalide",
                details="VÃ©rifiez votre clÃ© API dans la configuration",
                status_code=401
            )
        
        # Erreur gÃ©nÃ©rique
        return ClaudeAPIError(
            message="Erreur de l'assistant IA",
            details=str(error)
        )
    
    def _update_stats(self, success: bool, response_time: float, tokens_used: int = 0):
        """Met Ã  jour les statistiques d'usage."""
        self.stats["total_requests"] += 1
        
        if success:
            self.stats["successful_requests"] += 1
            self.stats["total_tokens_used"] += tokens_used
            
            # Moyenne glissante du temps de rÃ©ponse
            current_avg = self.stats["average_response_time"]
            total_requests = self.stats["total_requests"]
            self.stats["average_response_time"] = (
                (current_avg * (total_requests - 1) + response_time) / total_requests
            )
        else:
            self.stats["failed_requests"] += 1
        
        # MÃ©triques globales
        log_metrics.log_claude_call()  # On garde le mÃªme nom pour la compatibilitÃ©
    
    async def generate_response(
        self,
        user_message: str,
        context_documents: Optional[List[Dict[str, Any]]] = None,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        system_prompt_override: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re une rÃ©ponse Ã©ducative Ã  partir d'un message utilisateur.
        
        Args:
            user_message: Message de l'utilisateur
            context_documents: Documents RAG pour le contexte
            conversation_history: Historique de la conversation
            system_prompt_override: Prompt systÃ¨me personnalisÃ©
            
        Returns:
            Dict: RÃ©ponse avec mÃ©tadonnÃ©es
            
        Raises:
            ClaudeAPIError: Si erreur lors de l'appel API
        """
        start_time = time.time()
        
        try:
            # Construction du prompt systÃ¨me
            system_prompt = system_prompt_override or self._build_system_prompt(context_documents)
            
            # Construction des messages
            messages = self._build_messages(user_message, conversation_history, context_documents, system_prompt)
            
            self.logger.debug(f"ğŸ”µ Appel OpenAI - ModÃ¨le: {self.model}, Messages: {len(messages)}")
            
            # Appel Ã  l'API OpenAI
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                timeout=self.timeout
            )
            
            # Extraction de la rÃ©ponse
            response_text = response.choices[0].message.content if response.choices else ""
            
            # Calcul des mÃ©triques
            response_time = (time.time() - start_time) * 1000  # ms
            tokens_used = response.usage.total_tokens if response.usage else 0
            
            # Mise Ã  jour des stats
            self._update_stats(True, response_time, tokens_used)
            
            # Logging
            self.logger.info(
                f"âœ… RÃ©ponse OpenAI gÃ©nÃ©rÃ©e - "
                f"Tokens: {tokens_used}, Temps: {response_time:.0f}ms"
            )
            
            # Construction de la rÃ©ponse enrichie
            result = {
                "response": response_text,
                "model": self.model,
                "tokens_used": tokens_used,
                "response_time_ms": response_time,
                "has_context": bool(context_documents),
                "context_documents_count": len(context_documents) if context_documents else 0,
                "metadata": {
                    "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                    "completion_tokens": response.usage.completion_tokens if response.usage else 0,
                    "finish_reason": response.choices[0].finish_reason if response.choices else None,
                    "generated_at": time.time()
                }
            }
            
            return result
            
        except asyncio.TimeoutError:
            self._update_stats(False, (time.time() - start_time) * 1000)
            raise ClaudeTimeoutError(self.timeout)
            
        except Exception as e:
            self._update_stats(False, (time.time() - start_time) * 1000)
            self.logger.error(f"âŒ Erreur OpenAI API: {e}")
            raise self._handle_api_error(e)
    
    def _build_system_prompt(self, context_documents: Optional[List[Dict[str, Any]]] = None) -> str:
        """
        Construit le prompt systÃ¨me selon le contexte.
        
        Args:
            context_documents: Documents RAG optionnels
            
        Returns:
            str: Prompt systÃ¨me complet
        """
        if context_documents:
            return RAG_SYSTEM_PROMPT
        else:
            return EDUCATION_SYSTEM_PROMPT
    
    def _build_messages(
        self,
        user_message: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        context_documents: Optional[List[Dict[str, Any]]] = None,
        system_prompt: str = ""
    ) -> List[Dict[str, str]]:
        """
        Construit la liste des messages pour OpenAI.
        
        Args:
            user_message: Message utilisateur actuel  
            conversation_history: Historique des Ã©changes
            context_documents: Documents de contexte RAG
            system_prompt: Prompt systÃ¨me
            
        Returns:
            List: Messages formatÃ©s pour l'API OpenAI
        """
        messages = []
        
        # Message systÃ¨me (toujours en premier)
        if system_prompt:
            messages.append({
                "role": "system",
                "content": system_prompt
            })
        
        # Ajout de l'historique de conversation
        if conversation_history:
            for exchange in conversation_history[-5:]:  # Garde seulement les 5 derniers Ã©changes
                if exchange.get("user"):
                    messages.append({
                        "role": "user",
                        "content": exchange["user"]
                    })
                if exchange.get("assistant"):
                    messages.append({
                        "role": "assistant", 
                        "content": exchange["assistant"]
                    })
        
        # Construction du message utilisateur actuel
        current_message = user_message
        
        # Ajout du contexte RAG si disponible
        if context_documents:
            context_text = self._format_context_documents(context_documents)
            current_message = f"""Contexte Ã©ducatif disponible :
{context_text}

Question de l'utilisateur : {user_message}

RÃ©ponds en utilisant le contexte ci-dessus si pertinent, sinon rÃ©ponds avec tes connaissances gÃ©nÃ©rales. Adapte toujours ton langage pour des personnes peu alphabÃ©tisÃ©es."""
        
        messages.append({
            "role": "user",
            "content": current_message
        })
        
        return messages
    
    def _format_context_documents(self, context_documents: List[Dict[str, Any]]) -> str:
        """
        Formate les documents de contexte pour le prompt.
        
        Args:
            context_documents: Documents RAG avec scores
            
        Returns:
            str: Contexte formatÃ©
        """
        if not context_documents:
            return ""
        
        context_parts = []
        for i, doc in enumerate(context_documents[:3], 1):  # Max 3 documents
            content = doc.get("content", "").strip()
            score = doc.get("score", 0.0)
            
            if content:
                context_parts.append(f"Document {i} (pertinence: {score:.2f}) :\n{content}")
        
        return "\n\n".join(context_parts)
    
    async def generate_simple_response(self, user_message: str) -> str:
        """
        GÃ©nÃ¨re une rÃ©ponse simple sans contexte RAG.
        
        Args:
            user_message: Message de l'utilisateur
            
        Returns:
            str: RÃ©ponse gÃ©nÃ©rÃ©e
        """
        result = await self.generate_response(user_message)
        return result["response"]
    
    async def test_connection(self) -> Dict[str, Any]:
        """
        Teste la connexion Ã  l'API OpenAI.
        
        Returns:
            Dict: RÃ©sultat du test
        """
        try:
            start_time = time.time()
            
            # Test simple avec un message minimal
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Tu es un assistant de test."},
                    {"role": "user", "content": "Dis juste 'Test OK'"}
                ],
                max_tokens=10,
                temperature=0
            )
            
            response_time = (time.time() - start_time) * 1000
            
            return {
                "success": True,
                "model": self.model,
                "response_time_ms": response_time,
                "response": response.choices[0].message.content if response.choices else "",
                "tokens_used": response.usage.total_tokens if response.usage else 0
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "model": self.model
            }
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Retourne les statistiques d'usage du client.
        
        Returns:
            Dict: Statistiques dÃ©taillÃ©es
        """
        return {
            **self.stats,
            "success_rate": (
                self.stats["successful_requests"] / max(self.stats["total_requests"], 1)
            ) * 100,
            "model": self.model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature
        }
    
    def reset_stats(self):
        """Remet Ã  zÃ©ro les statistiques."""
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_tokens_used": 0,
            "average_response_time": 0.0
        }
        self.logger.info("ğŸ“Š Statistiques remises Ã  zÃ©ro")
    
    async def close(self):
        """Ferme proprement le client."""
        try:
            await self.client.close()
            self.logger.info("ğŸ”’ Client OpenAI fermÃ©")
        except Exception as e:
            self.logger.warning(f"Erreur lors de la fermeture: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª FONCTIONS DE TEST
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def test_openai_client():
    """Teste le client OpenAI avec diffÃ©rents scÃ©narios."""
    import os
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY manquante dans l'environnement")
        return
    
    print("ğŸ§ª Test du client OpenAI...")
    
    client = OpenAIClient(
        api_key=api_key,
        model="gpt-3.5-turbo",
        max_tokens=100
    )
    
    # Test de connexion
    print("\n1. Test de connexion...")
    connection_test = await client.test_connection()
    if connection_test["success"]:
        print(f"âœ… Connexion OK - {connection_test['response']}")
    else:
        print(f"âŒ Connexion Ã©chouÃ©e: {connection_test['error']}")
        return
    
    # Test de rÃ©ponse simple
    print("\n2. Test de rÃ©ponse Ã©ducative...")
    try:
        response = await client.generate_simple_response(
            "Explique-moi ce que c'est qu'une addition"
        )
        print(f"âœ… RÃ©ponse: {response[:100]}...")
    except Exception as e:
        print(f"âŒ Erreur: {e}")
    
    # Test avec contexte RAG
    print("\n3. Test avec contexte RAG...")
    mock_documents = [
        {
            "content": "L'addition est une opÃ©ration qui permet de rassembler plusieurs nombres pour en obtenir un seul, appelÃ© somme.",
            "score": 0.95
        }
    ]
    
    try:
        result = await client.generate_response(
            "Comment faire une addition ?",
            context_documents=mock_documents
        )
        print(f"âœ… RÃ©ponse avec RAG: {result['response'][:100]}...")
        print(f"   Tokens utilisÃ©s: {result['tokens_used']}")
    except Exception as e:
        print(f"âŒ Erreur RAG: {e}")
    
    # Statistiques
    print("\n4. Statistiques:")
    stats = client.get_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    # Fermeture
    await client.close()
    print("\nâœ… Test terminÃ©!")


if __name__ == "__main__":
    asyncio.run(test_openai_client())